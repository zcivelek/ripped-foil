---
title: "Patterned Paper Control - Monkeys"
author: "Zeynep Civelek"
date: "June 30, 2020"
output: word_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, include=TRUE)

#This sets general options for the code chunks in the R Markdown file. The echo, warning, and message = FALSE hide the code chunks, warning messages, and other messages, where the ‘include=true’ will make all figures appear in the text. You can set some of these variables to TRUE, and hit Knit to see what they change. 
```

```{r, include=FALSE}
#PREPARE
R.Version()#for referencing, shows you which R version you are using
rm(list=ls())#removes any other items in your workspace
ls()#check whether workspace is empty
```

```{r, include=FALSE}
#Directory is set, data is added and all the libraries necessary for running the analyses are loaded.

conmon1<-read.csv("ripped_monkey_control16.csv", header=T)
# setwd("C:/Users/Zeynep/Desktop/ripped-foil/Ripped Foil")
# ripchild<-read.csv("ripped_child.csv", header=T)
#all the libraries necessary to run the analyses
library(lme4)
library(readr)
library(tidyverse)
library(sjPlot)
#install.packages('TMB', type='source')
library(ggthemes)
library(gridExtra)
library(reshape2)
library(car)
#library(psych)
library("ggpubr")
library(dplyr)

```
##Exploring data 

The structure of the data is shown below with all the variable names and levels of measurement.

```{r, echo=FALSE}
conmon1$id<-as.factor(conmon1$id)
conmon1$sex<-as.factor(conmon1$sex)
conmon1$phase2<-as.factor(conmon1$phase2)

str(conmon1)

```

Exploring the warm-up 1 (the cups are initially empty/not covered and after the hiding event the baited cup is covered with patterned paper and the empty cup is covered with white paper) and warm-up 2 phases (the cups are initially covered with white paper and after the hiding event, the baited cup is covered with patterned paper).

```{r, echo=FALSE}
conmon_complete<-read.csv("control_monkey_complete.csv", header=T)
conmon_warm1 <- conmon_complete %>%
  filter(sessiontype=="pattern-warmup1") %>%
  group_by(id, sex, age, sessionno, trialno) %>% 
  summarize(correct)

conmon_warm2 <- conmon_complete %>%
  filter(sessiontype=="pattern-warmup2") %>%
  group_by(id, sex, age, sessionno, trialno) %>% 
  summarize(correct)

range(conmon_warm1$sessionno)
range(conmon_warm2$sessionno)
```

**In warm-up 1, monkeys received up to 11 sessions to reach criterion and in warm-up 2, up to 2 sessions (or they'd receive up to 10 sessions). The minimum number of sessions to reach criterion was 2 (14/16 correct)**

##Histograms for Warm-up 1 and Warm-up 2 Phases
```{r, echo=FALSE}
agg_warm1 <- aggregate(conmon_warm1$correct, by = list(id = conmon_warm1$id), function(x) c(mean = mean(x), sd = sd(x), n = length(x)))
agg_warm1 <- do.call(data.frame, agg_warm1)
agg_warm1$se <- agg_warm1$x.sd / sqrt(agg_warm1$x.n)

colnames(agg_warm1) <- c("id", "mean", "sd", "n", "se")

agg_warm1$names <- c(paste(agg_warm1$id, "id"))

limits <- aes(ymax = agg_warm1$mean + agg_warm1$se,
              ymin = agg_warm1$mean - agg_warm1$se)

hist(agg_warm1$mean, xlab="Mean score in Warm-up 1", xlim=c(0,1))

agg_warm2 <- aggregate(conmon_warm2$correct, by = list(id = conmon_warm2$id), function(x) c(mean = mean(x), sd = sd(x), n = length(x)))
agg_warm2 <- do.call(data.frame, agg_warm2)
agg_warm2$se <- agg_warm2$x.sd / sqrt(agg_warm2$x.n)

colnames(agg_warm2) <- c("id", "mean", "sd", "n", "se")

agg_warm2$names <- c(paste(agg_warm2$id, "id"))

limits <- aes(ymax = agg_warm2$mean + agg_warm2$se,
              ymin = agg_warm2$mean - agg_warm2$se)

hist(agg_warm2$mean, xlab="Mean score in Warm-up 2", xlim=c(0,1), ylim=c(0,12))

```
**The data shows that after the initial warm up phase, the monkeys very quickly learnt to find the reward in the patterned cup.**

I then aggregated the trial-by-trial data to create one score per monkey for Test and Transfer phases so I can see the distribution of scores.

```{r, echo=FALSE}
conmon_individual <- conmon1 %>%
  filter(!is.na(correct)) %>%
  group_by(id) %>% 
  summarize(correct = mean(correct))%>%
  add_count(correct)

conmon_test <- conmon1 %>%
   filter(!is.na(correct)) %>%
  filter(phase=="pattern-test") %>%
  group_by(id) %>% 
  summarize(correct = mean(correct))%>%
  add_count(correct)

conmon_transfer <- conmon1 %>%
   filter(!is.na(correct)) %>%
  filter(phase=="pattern-transfer") %>%
  group_by(id) %>% 
  summarize(correct = mean(correct))%>%
  add_count(correct)

conmon_separate <- conmon1 %>%
  group_by(phase,id) %>% 
  summarize(correct = mean(correct))%>%
  add_count(correct)


```

##Histograms for Test and Transfer Phases and the overall score

```{r}
hist(conmon_test$correct, xlab="Mean score in Test", xlim=c(0,1))
hist(conmon_transfer$correct, xlab="Mean score in Transfer", xlim=c(0,1))
hist(conmon_individual$correct, xlab="Overall score (Test and Transfer)", xlim=c(0,1))
```

##Below is how performance looks in the last 16 trials of Test and Transfer
```{r, echo=FALSE}
boxplot1 <- ggplot(conmon_separate, aes(x=phase, y=correct)) + 
    geom_dotplot(binaxis='y', stackdir='center', dotsize=0.5) + ylim(0,1)
boxplot1 + stat_summary(fun.data="mean_sdl", fun.args = list(mult=1), geom="crossbar", width=0.5) + stat_summary(fun=mean, geom="point", color="red")+theme_bw() + stat_summary(fun.data=mean_sdl, fun.args = list(mult=1), 
                 geom="pointrange", color="red")+ theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+geom_hline(yintercept=0.50, color='red', linetype="dashed")+xlab("Phase") + ylab("Mean number of correct responses in 16 trials")
```

##Preparation of the data for running the GLMM

* Scaling age and trial number
* Coding categorical variables (trial type, sex, phase) as dummy variables 
* Centering the slopes.

```{r, echo=FALSE}
#We scale variables so that the differences in the range of the variables do not influence the parameter estimations.
conmon1$z.trialno<-as.vector(scale(conmon1$trialno))
conmon1$z.age=as.vector(scale(conmon1$age))
conmon1$trialtype<-relevel(conmon1$trialtype, ref = "stick")

#coding dummy variables before centering the slopes
conmon1$trialtype.food<-as.numeric(conmon1$trialtype==levels(conmon1$trialtype)[2])
conmon1$sex.m<-as.numeric(conmon1$sex==levels(conmon1$sex)[2])
conmon1$phase.transfer=as.numeric(conmon1$phase==levels(conmon1$phase)[2])

#centering the slopes: p-values of the factors can be influenced by the choice of reference category.
#by centering the factor for the random slope components the p-values should be the same irrespective of the choice of the reference level
conmon1$trialtype.food.c<-conmon1$trialtype.food-mean(conmon1$trialtype.food)
conmon1$phase.transfer.c=conmon1$phase.transfer-mean(conmon1$phase.transfer)
conmon1$sex.m.c<-conmon1$sex.m -mean(conmon1$sex.m)

```

```{r, echo=FALSE}
source("./Roger_functions/diagnostic_fcns.r")
source("./Roger_functions/glmm_stability.r")
source("./Roger_functions/boot_glmm.r")
```

##Full model 

```{r, echo=TRUE}
contr<-glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=10000000))
full=glmer(correct ~ trialtype*phase+z.trialno+z.age+sex+(1|id)+(0+z.trialno+phase.transfer.c+trialtype.food.c|id),data=conmon1, family=binomial, control=contr)
```

The full model does not include box type (the location of the blue/pink box) as a random effect anymore due to convergence issues. There is the singular fit warning here and throughout though.

##Model assumptions

####Distribution of random effects
```{r, echo=FALSE}
#An assumption of GLMMs is that the BLUPs are normally distributed. We use the following function to evaluate this. BLUPs are Best Linear Unbiased Predictors: the estimated grouping factor's level specific deviation from the common intercept or slope.
ranef.diagn.plot(full)
```

####Model stability

```{r, echo=FALSE}
#summary reveals min and max of the estimates obtained after casewise deletion of levels of random effects together with the original estimates.
# m.stab=glmm.model.stab(model.res=full, contr=contr)
# m.stab.plot(m.stab$summary[,-1])
# m.stab$summary
# m.stab$detailed$warnings
```

####Multicollinearity

```{r, echo=FALSE}
coll=lm(correct ~ trialtype+phase+z.trialno+z.age+sex, data=conmon1)
round(vif(coll),3)
#no vif issues
```

##Null model

```{r, echo=TRUE}
null=glmer(correct~ z.trialno + (1|id)+(0+z.trialno+phase.transfer.c+trialtype.food.c|id),data=conmon1, family=binomial, control=contr)
```
Trialno is added to the null model.


##Full and Null comparison
```{r, echo=FALSE}
round(anova(null, full, test="Chisq"),3)
```

##Model output

####Coefficients

```{r, echo=FALSE}
round(summary(full)$coefficients, 3)
```

####Individual predictor: Likelihood tests

```{r, echo=FALSE}
xdrop1=drop1(full, test="Chisq",control=contr)
round(xdrop1,3)
```


```{r, include=FALSE}
####Confidence intervals for the full model with the interaction

#conmon_model1=boot.glmm.pred(model.res=full, excl.warnings=T, nboots=1000, para=T)
#save.image("conmon_model1_CIs.RData")
load("conmon_model1_CIs.RData")
round(conmon_model1$ci.estimates, 3)
```

**The null and full models are significantly different from each other. But the interaction term is not significant. I will remove this next to see if it improves the model.**

##Reduced model without the interaction
##Full model 2
```{r, echo=TRUE}
full2=glmer(correct ~ trialtype+phase+z.trialno+z.age+sex+(1|id)+(0+z.trialno+phase.transfer.c+trialtype.food.c|id),data=conmon1, family=binomial, control=contr)
summary(full2)
```

I get the following warning: convergence code: 0, boundary (singular) fit: see ?isSingular.

##Null model 2

```{r, echo=TRUE}
null2<-glmer(correct~z.trialno+(1|id)+(0+z.trialno+phase.transfer.c+trialtype.food.c|id),data=conmon1, family=binomial, control=contr)
```

##Full and null model (2) comparion
```{r, echo=FALSE}
round(anova(null2, full2, test="Chisq"),3)
```

##Model output

####Coefficients

```{r, echo=FALSE}
round(summary(full2)$coefficients, 3)

```

####Individual predictors : Likelihood ratio tests
  
```{r echo=FALSE}
xdrop1=drop1(full2, test="Chisq",control=contr)
round(xdrop1,3)
```
**The model without the interaction is significantly different from the null model too. There is no effect of phase in this case, but trial type has a significant effect on performance. There is a trend for age to have an effect on performance as well but I'm not going to further explore this as we had no apriori expectations about age for monkeys.**

```{r, include=FALSE}
# this is for me to check the variance added by random effects, number of observations and subjects etc.
print(summary(full2), corr=FALSE)
```


```{r, include=FALSE}
####Confidence intervals for the reduced model without the interaction

#conmon_model2=boot.glmm.pred(model.res=full2, excl.warnings=T, nboots=1000, para=T)
#save.image("conmon_model2_CIs.RData")
load("conmon_model2_CIs.RData")
round(conmon_model2$ci.estimates, 3)
```

##Plotting the findings
```{r, echo=FALSE}
p1 <- ggplot(data=conmon_separate, aes(x=phase, y=correct, group=phase)) + geom_boxplot()+ylim(0,1)+geom_point(size = conmon_separate$n, colour = "darkgrey", alpha=0.3) + geom_line(aes(group = id), colour = "darkgrey", alpha = 0.5)+labs(x="",y="Mean number of correct choices")+theme_few()+ggtitle("Phase")+geom_hline(yintercept=0.5, linetype="dashed", color = "red")

conmon_individual2 <- conmon1 %>% 
  group_by(trialtype, id) %>% 
  summarize(correct = mean(correct)) %>% 
  add_count(correct)
p2 <- ggplot(data=conmon_individual2, aes(x=trialtype, y=correct, group=trialtype)) +geom_boxplot()+ylim(0,1)+geom_point(size = conmon_individual2$n, colour = "darkgrey", alpha=0.3) +geom_line(aes(group = id), colour = "darkgrey", alpha = 0.5)+labs(x="",y="Mean number of correct choices")+ theme_few()+ggtitle("Trial type")+geom_hline(yintercept=0.5, linetype="dashed", color = "red")


grid.arrange(p1, p2, nrow = 1, heights=unit(100, "mm"))
```


##Test against chance
####Test and transfer phase

```{r, echo=TRUE}
testphase <-conmon1%>%
  filter(phase == "pattern-test")
testchance <- glmer(correct ~ 1 + (z.trialno | id), data= testphase, family=binomial)
summary(testchance)
```
```{r, echo=TRUE}
transferphase <-conmon1%>%
  filter(phase == "pattern-transfer")
transferchance <- glmer(correct ~ 1 + (z.trialno | id), data= transferphase, family=binomial)
summary(transferchance)
```
This is a change now and is interesting! Performance at Test seems to be above chance **(barely)** and Transfer is not **(barely?)**. The thing is most of the monkeys performed at chance in Test, but there are 3 who did really well and I suspect they are bringing the mean up (**Q:** Is the intercept a good test in such cases?). Moreover, these monkeys got the food-stick trials in Test. When they switched in Transfer, performance dropped. Conversely the ones who did well in Transfer were the ones who got food-stick trials. It is incredible that phase and trial type interaction wasn't significant in the first model...
This is a very tricky finding. I think it shows that monkeys can perform well in this task (both patterned and ripped) when the memory demands are low and they do not need to engage in any reasoning at all. And I think this jeopardizes the positive findings from the ripped foil a little but doesn't explain it fully as they performed much better in that task than here. Looking forward to discussing these!


####Trial type

```{r, echo=FALSE}
sticktrials <-conmon1%>%
  filter(trialtype == "stick")
stickchance <- glmer(correct ~ 1 + (z.trialno | id),data= sticktrials, family=binomial)
summary(stickchance)

foodtrials <-conmon1%>%
  filter(trialtype == "food")
foodchance <- glmer(correct ~ 1 + (z.trialno | id),data= foodtrials, family=binomial)
summary(foodchance)
```
Performance is not different from chance level in stick-food trials and it is above chance in food-stick trials as it is also clearly seen in the plot.

##Correcting the p-values for the post-hoc tests using Hochberg correction (in the order: test, transfer, stick-food, food-stick)

```{r, echo=TRUE}
pvalues <- c(0.0463, 0.0811, 0.789, 0.00746)
p.adjust(pvalues, method="hochberg")
```
**OK, maybe I spoke too soon about the Test, Transfer phase results here- the corrected p-values show that these are not significant, only the performance in food-stick trials is above chance. But we may decide to discuss the performance of those 5 monkeys (3 in test and 2 in transfer) who did really well in this task regardless of p-values, right?**


####How about the first trial performance in Transfer phase: Is performance above chance?

```{r, echo=TRUE}
conmon_1st_trial <- conmon1 %>%
  filter(phase=="pattern-transfer" & sessionno=="1", trialno=="1")
#I am fitting a glm with binomial error structure for the first trial transfer phase analysis and not a mixed model given that it only includes one data point per subject.
firsttrialchance <- glm(correct ~ 1, data= conmon_1st_trial, family=binomial)
summary(firsttrialchance)
```
```{r}
sum(conmon_1st_trial$correct)
length(conmon_1st_trial$correct)

binom.test(x=sum(conmon_1st_trial$correct), n=length(conmon_1st_trial$correct), p=0.5, alternative = "two.sided")
```

**No, performance in the first trial of transfer does not differ from chance level.**



```{r, include=FALSE}
###monkey figure similar to children

controlaggregate <- aggregate(conmon1$correct, by = list(phase = conmon1$phase), function(x) c(mean = mean(x), sd = sd(x), n = length(x)))
controlaggregate <- do.call(data.frame, controlaggregate)
controlaggregate$se <- controlaggregate$x.sd / sqrt(controlaggregate$x.n)

colnames(controlaggregate) <- c("phase", "mean", "sd", "n", "se")

controlaggregate$names <- c(paste(controlaggregate$phase, "phase"))

limits <- aes(ymax = controlaggregate$mean + controlaggregate$se,
              ymin = controlaggregate$mean - controlaggregate$se)
p <- ggplot(data = controlaggregate, aes(x = factor(phase), y = mean, fill = factor(phase)))
p + geom_bar(stat = "identity", position = position_dodge(0.9), width = 0.8) + geom_errorbar(limits, position = position_dodge(0.9), width = 0.10) + labs(x = "", y = "Mean number of correct choices") + ggtitle("Performance in the arbitrary follow up") +scale_fill_grey(name = "Phase") + geom_hline(yintercept=0.50, linetype="dashed", color="red", size=1)  + theme(legend.text = element_text(size = 8)) + ylim(0.00,1.00) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),panel.background = element_blank())


```


```{r}
corrmon<-read.csv("monkey correlation food.csv", header=T)
corrmon_food <- corrmon %>%
  filter(trialtype=="food") %>%
  group_by(id) 

corrmon_stick <- corrmon %>%
  filter(trialtype=="stick") %>%
  group_by(id) 


corrfood_individual <- corrmon_food %>%
  filter(!is.na(concorrect))%>%
  group_by(id) %>%
  summarize(correct1 = mean(ripcorrect), correct2=mean(concorrect))

corrstick_individual <- corrmon_stick %>%
  filter(!is.na(concorrect))%>%
  group_by(id) %>%
  summarize(correct1 = mean(ripcorrect), correct2=mean(concorrect))



#install.packages("Hmisc")
#install.packages("ggm")
#install.packages("polycor")
library(Hmisc)
library(ggm)
library(polycor)


scattercorr<-ggplot(corrfood_individual, aes(correct1, correct2))
scattercorr+geom_point()
cor.test(corrfood_individual$correct1, corrfood_individual$correct2, alternative="two.sided", method="pearson")


scattercorr2<-ggplot(corrstick_individual, aes(correct1, correct2))
scattercorr2+geom_point()
cor.test(corrstick_individual$correct1, corrstick_individual$correct2, alternative="two.sided", method="pearson")

#they are not normally distributed so ran a bootstrapping correlation..
boot1<-function(corrfood_individual, i)cor(corrfood_individual$correct1[i],corrfood_individual$correct2[i], use="complete.obs", method="pearson")
library(boot)
boot_food<-boot(corrfood_individual, boot1, 2000)
boot_food
boot.ci(boot_food)
#the bias is very small and the normal CI does not include 0 so we can be sure that the positive correlation is meaningful for food-stick trials in Exp 2 and 3

boot2<-function(corrstick_individual, i)cor(corrstick_individual$correct1[i],corrstick_individual$correct2[i], use="complete.obs", method="pearson")
boot_stick<-boot(corrstick_individual, boot2, 2000)
boot_stick
boot.ci(boot_stick)
#I would retain the results for the stick trials as well. The bias is very small but the CIs include the 0. We cannot say the correlation is meaningful. 
```


